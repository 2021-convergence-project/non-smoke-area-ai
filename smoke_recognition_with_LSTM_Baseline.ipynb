{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a70bc4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표: DACON Baseline 코드를 이용해 LSTM을 활용한 학습 진행\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "\n",
    "import os\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b18128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_aihub_annotation(keypoint):\n",
    "    # 학습데이터는 모두 2D데이터\n",
    "    # 따라서, 사용하지 않는 값 (_, _, 2)을 제거\n",
    "    keypoint = keypoint.reshape(-1, 3)\n",
    "    result = np.delete(keypoint, 2, axis=1)\n",
    "    \n",
    "    # 실제 예측에서 사용할 수 없는 Annotation 제거\n",
    "    result = np.delete(result, [6,7,8], axis=0)\n",
    "    result = result.reshape(1,-1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb828980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(96,)\n",
      "96\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 960.   585.   969.  ...  414.   960.   411. ]\n",
      " [1252.   664.  1256.  ...  507.  1202.   515. ]\n",
      " [ 928.   654.   944.  ...  469.   943.   464. ]\n",
      " ...\n",
      " [ 786.   613.   731.5 ...  437.   807.   486. ]\n",
      " [ 756.   635.   737.  ...  420.   745.   420. ]\n",
      " [ 830.   863.   834.  ...  597.   864.   639. ]]\n",
      "(96, 26)\n",
      "96\n",
      "[ 960.  585.  969.  519.  994.  455.  994.  459.  994.  525. 1035.  594.\n",
      "  985.  317.  972.  411.  988.  418.  997.  380.  988.  377.  978.  414.\n",
      "  960.  411.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./test_data/output.csv', sep=',')\n",
    "\n",
    "KEYPOINT = 32\n",
    "KEYPOINT_MOD = 26\n",
    "\n",
    "# CSV파일 구조:\n",
    "# 액션시나리오번호_촬영순번-C카메라번호\n",
    "# 45-1_001-C3 / 0 / 키포인트\n",
    "\n",
    "\n",
    "x_data = df[['Keypoints']]\n",
    "t_data = np.zeros(96,)\n",
    "print(t_data)\n",
    "# t_data = df[['ID']]\n",
    "\n",
    "keypoint = np.array(x_data['Keypoints'].values)\n",
    "keypoint_arr = np.empty((0,KEYPOINT_MOD), float)\n",
    "\n",
    "for i in range(0, len(keypoint)) :\n",
    "    keypoint[i] = keypoint[i].replace(\"[\", \"\")\n",
    "    keypoint[i] = keypoint[i].replace(\"]\", \"\")\n",
    "    keypoint[i] = keypoint[i].split(',')\n",
    "\n",
    "    # keypoint[0]\n",
    "    nd_array = np.array(keypoint[i])\n",
    "    nd_array = nd_array.astype(np.float)\n",
    "#     print(\"nd_array\")\n",
    "#     print(nd_array)\n",
    "\n",
    "    # 학습데이터는 모두 2D데이터\n",
    "    # 사용하지 않는 값과 사용할 수 없는 annotation을 제거\n",
    "    result = remove_aihub_annotation(nd_array)\n",
    "#     print(result)\n",
    "#     print(result.shape)\n",
    "#     print(type(result[0][0]))\n",
    "\n",
    "    keypoint_arr = np.append(keypoint_arr, result, axis=0)\n",
    "\n",
    "print(keypoint.shape)\n",
    "print(len(keypoint))\n",
    "    \n",
    "print(type(keypoint_arr))\n",
    "print(keypoint_arr)\n",
    "print(keypoint_arr.shape)\n",
    "print(len(keypoint_arr))\n",
    "print(keypoint_arr[0])\n",
    "print(type(keypoint_arr[0])) # <class 'str'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d25e7d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Keypoints\n",
      "0      [967.0, 652.0, 2.0, 981.0, 575.0, 2.0, 991.0, ...\n",
      "1      [949.0, 657.0, 2.0, 947.0, 582.0, 2.0, 955.0, ...\n",
      "2      [970.0, 649.0, 2.0, 995.0, 575.0, 2.0, 1006.0,...\n",
      "3      [950.0, 656.0, 2.0, 939.0, 582.0, 2.0, 940.0, ...\n",
      "4      [1037.0, 649.0, 2.0, 1037.0, 572.0, 2.0, 1036....\n",
      "...                                                  ...\n",
      "52077  [930.0, 738.0, 2.0, 921.0, 649.0, 2.0, 913.0, ...\n",
      "52078  [1100.0, 713.0, 2.0, 1051.0, 627.0, 2.0, 1018....\n",
      "52079  [930.0, 734.0, 2.0, 913.0, 649.0, 2.0, 888.0, ...\n",
      "52080  [1108.0, 721.0, 2.0, 1087.0, 627.0, 2.0, 1056....\n",
      "52081  [910.0, 737.0, 2.0, 879.0, 654.0, 2.0, 846.0, ...\n",
      "\n",
      "[52082 rows x 1 columns]\n",
      "52082\n",
      "(52082, 1)\n",
      "(52082,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 52082/52082 [00:25<00:00, 2018.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 967.  652.  981. ...  389. 1095.  371.]\n",
      " [ 949.  657.  947. ...  445.  869.  497.]\n",
      " [ 970.  649.  995. ...  467. 1096.  505.]\n",
      " ...\n",
      " [ 930.  734.  913. ...  499.  906.  548.]\n",
      " [1108.  721. 1087. ...  468. 1059.  521.]\n",
      " [ 910.  737.  879. ...  505.  844.  541.]]\n",
      "(52082, 26)\n",
      "52082\n",
      "[ 967.  652.  981.  575.  991.  484. 1030.  486. 1044.  578. 1061.  652.\n",
      " 1009.  333.  938.  333.  963.  362.  984.  393. 1037.  400. 1069.  389.\n",
      " 1095.  371.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./test_data/5.csv', sep=',')\n",
    "\n",
    "KEYPOINT = 32\n",
    "KEYPOINT_MOD = 26\n",
    "\n",
    "# CSV파일 구조:\n",
    "# 45-1_001-C3 / 0 / 키포인트\n",
    "\n",
    "# 5-7_016-C12\n",
    "# 41-9_016-C12\n",
    "# 6-7_603-C09\n",
    "\n",
    "def get_keypoints_in_float(string_data):\n",
    "    keypoint = np.array(string_data['Keypoints'].values)\n",
    "    print(keypoint.shape)\n",
    "    keypoint_arr = np.empty((0,KEYPOINT_MOD), float)\n",
    "\n",
    "#     i=0\n",
    "    for i in tqdm(range(0, len(keypoint))) :\n",
    "        keypoint[i] = keypoint[i].replace(\"[\", \"\")\n",
    "        keypoint[i] = keypoint[i].replace(\"]\", \"\")\n",
    "        keypoint[i] = keypoint[i].split(',')\n",
    "\n",
    "        # keypoint[0]\n",
    "        nd_array = np.array(keypoint[i])\n",
    "        nd_array = nd_array.astype(np.float)\n",
    "    #     print(\"nd_array\")\n",
    "    #     print(nd_array)\n",
    "    #     print(nd_array.shape)\n",
    "\n",
    "        # 학습데이터는 모두 2D데이터\n",
    "        # 사용하지 않는 값과 사용할 수 없는 annotation을 제거\n",
    "        result = remove_aihub_annotation(nd_array)\n",
    "    #     print(result)\n",
    "    #     print(result.shape)\n",
    "    #     print(type(result[0][0]))\n",
    "\n",
    "        keypoint_arr = np.append(keypoint_arr, result, axis=0)\n",
    "    return keypoint_arr\n",
    "\n",
    "\n",
    "x_data = df[['Keypoints']]\n",
    "t_data = np.zeros(len(x_data),)\n",
    "print(x_data)\n",
    "print(len(x_data))\n",
    "print(x_data.shape)\n",
    "# print(t_data)\n",
    "# t_data = df[['ID']]\n",
    "\n",
    "x_data_mod = get_keypoints_in_float(x_data)\n",
    "\n",
    "# print(keypoint.shape)\n",
    "# print(len(keypoint))\n",
    "    \n",
    "print(type(x_data_mod))\n",
    "print(x_data_mod)\n",
    "print(x_data_mod.shape)\n",
    "print(len(x_data_mod))\n",
    "print(x_data_mod[0])\n",
    "print(type(x_data_mod[0])) # <class 'str'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b20d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# train=pd.read_csv('train_features.csv')\n",
    "# train_labels=pd.read_csv('train_labels.csv')\n",
    "# test=pd.read_csv('test_features.csv')\n",
    "# submission=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9640ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    " \n",
    "args = easydict.EasyDict({\n",
    "        \"batchsize\": 128,\n",
    "        \"epoch\": 38,\n",
    "#         \"gpu\": 0,\n",
    "        \"out\": \"result\",\n",
    "        \"resume\": False,\n",
    "#         \"unit\": 1000,\n",
    "        \"validationsplit\": 0.2,\n",
    "        \"optimizer\": \"rmsprop\",\n",
    "#         \"optimizer\": \"Adam\",\n",
    "        \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ -1, (한번에 들어갈 입력값 수), (좌표개수) ]\n",
    "# 13개의 x,y 좌표이므로 26개\n",
    "X=tf.reshape(np.array(train.iloc[:,2:]),[-1, 19, 26])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f31bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(train_labels['label']) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#가벼운 모델 생성\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(19,26)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(61, activation='softmax')) # 다중 분류\n",
    "model.add(Dense(61, activation='sigmoid'))\n",
    "\n",
    "# Adam 최적화함수를 사용해보는 것도 고려해볼 것\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) # 다중 분류\n",
    "model.compile(optimizer=args.optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y, epochs=args.epoch, batch_size=args.batchsize, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41807bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=tf.reshape(np.array(test.iloc[:,2:]),[-1, 19, 26])\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c7985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e8719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81484b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c77da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env24] *",
   "language": "python",
   "name": "conda-env-data_env24-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
