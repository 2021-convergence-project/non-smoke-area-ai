{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "smoke_recognition_with_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb828980"
      },
      "source": [
        "# df = pd.read_csv('./test_data/output.csv', sep=',')\n",
        "\n",
        "# KEYPOINT = 32\n",
        "# KEYPOINT_MOD = 26\n",
        "\n",
        "# # CSV파일 구조:\n",
        "# # 액션시나리오번호_촬영순번-C카메라번호\n",
        "# # 45-1_001-C3 / 0 / 키포인트\n",
        "\n",
        "\n",
        "# x_data = df[['Keypoints']]\n",
        "# t_data = np.zeros(96,)\n",
        "# print(t_data)\n",
        "# # t_data = df[['ID']]\n",
        "\n",
        "# keypoint = np.array(x_data['Keypoints'].values)\n",
        "# keypoint_arr = np.empty((0,KEYPOINT_MOD), float)\n",
        "\n",
        "# for i in range(0, len(keypoint)) :\n",
        "#     keypoint[i] = keypoint[i].replace(\"[\", \"\")\n",
        "#     keypoint[i] = keypoint[i].replace(\"]\", \"\")\n",
        "#     keypoint[i] = keypoint[i].split(',')\n",
        "\n",
        "#     # keypoint[0]\n",
        "#     nd_array = np.array(keypoint[i])\n",
        "#     nd_array = nd_array.astype(np.float)\n",
        "# #     print(\"nd_array\")\n",
        "# #     print(nd_array)\n",
        "\n",
        "#     # 학습데이터는 모두 2D데이터\n",
        "#     # 사용하지 않는 값과 사용할 수 없는 annotation을 제거\n",
        "#     result = remove_aihub_annotation(nd_array)\n",
        "# #     print(result)\n",
        "# #     print(result.shape)\n",
        "# #     print(type(result[0][0]))\n",
        "\n",
        "#     keypoint_arr = np.append(keypoint_arr, result, axis=0)\n",
        "\n",
        "# print(keypoint.shape)\n",
        "# print(len(keypoint))\n",
        "    \n",
        "# print(type(keypoint_arr))\n",
        "# print(keypoint_arr)\n",
        "# print(keypoint_arr.shape)\n",
        "# print(len(keypoint_arr))\n",
        "# print(keypoint_arr[0])\n",
        "# print(type(keypoint_arr[0])) # <class 'str'>\n",
        "\n"
      ],
      "id": "cb828980",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrj31qZ1o2-l",
        "outputId": "82e8fe4b-b837-46ff-e12c-4b8b2db3564e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "nrj31qZ1o2-l",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c83e09a"
      },
      "source": [
        "# 목표: DACON Baseline 코드를 이용해 LSTM을 활용한 학습 진행"
      ],
      "id": "0c83e09a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1a9640ef"
      },
      "source": [
        "import tensorflow as tf\n",
        "# tf.__version__\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "# session = tf.Session(config=config....)\n",
        "\n",
        "# physical_devices = tf.config.list_physical_devices('GPU') \n",
        "# for device in physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#     # 텐서플로가 첫 번째 GPU에 1GB 메모리만 할당하도록 제한\n",
        "#     try:\n",
        "#         tf.config.experimental.set_virtual_device_configuration(\n",
        "#             gpus[0],\n",
        "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
        "#     except RuntimeError as e:\n",
        "#         # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
        "#         print(e)\n",
        "    \n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM"
      ],
      "id": "1a9640ef",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "654ecf86",
        "outputId": "f8737510-22e6-4eee-e399-8efe9a850ca2"
      },
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "# physical_devices = tf.config.list_physical_devices('GPU') \n",
        "# for device in physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)"
      ],
      "id": "654ecf86",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b20d807"
      },
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# train=pd.read_csv('train_features.csv')\n",
        "# train_labels=pd.read_csv('train_labels.csv')\n",
        "# test=pd.read_csv('test_features.csv')\n",
        "# submission=pd.read_csv('sample_submission.csv')"
      ],
      "id": "2b20d807",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a70bc4e1"
      },
      "source": [
        "# 목표: DACON Baseline 코드를 이용해 LSTM을 활용한 학습 진행\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import io\n",
        "\n",
        "import os\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from scipy import stats"
      ],
      "id": "a70bc4e1",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b18128f"
      },
      "source": [
        "# def remove_aihub_annotation(keypoint):\n",
        "#     # 학습데이터는 모두 2D데이터\n",
        "#     # 따라서, 사용하지 않는 값 (_, _, 2)을 제거\n",
        "#     keypoint = keypoint.reshape(-1, 3)\n",
        "#     result = np.delete(keypoint, 2, axis=1)\n",
        "    \n",
        "#     # 실제 예측에서 사용할 수 없는 Annotation 제거\n",
        "#     result = np.delete(result, [6,7,8], axis=0)\n",
        "#     result = result.reshape(1,-1)\n",
        "    \n",
        "#     return result"
      ],
      "id": "0b18128f",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96637978"
      },
      "source": [
        "# def get_keypoints_in_float(string_data):\n",
        "#     keypoint = np.array(string_data['Keypoints'].values)\n",
        "#     print(keypoint.shape)\n",
        "#     keypoint_arr = np.empty((0,KEYPOINT_MOD), float)\n",
        "\n",
        "# #     i=0\n",
        "#     for i in tqdm(range(0, len(keypoint))) :\n",
        "#         keypoint[i] = keypoint[i].replace(\"[\", \"\")\n",
        "#         keypoint[i] = keypoint[i].replace(\"]\", \"\")\n",
        "#         keypoint[i] = keypoint[i].split(',')\n",
        "\n",
        "#         # keypoint[0]\n",
        "#         nd_array = np.array(keypoint[i])\n",
        "#         nd_array = nd_array.astype(np.float)\n",
        "#     #     print(\"nd_array\")\n",
        "#     #     print(nd_array)\n",
        "#     #     print(nd_array.shape)\n",
        "\n",
        "#         # 학습데이터는 모두 2D데이터\n",
        "#         # 사용하지 않는 값과 사용할 수 없는 annotation을 제거\n",
        "#         result = remove_aihub_annotation(nd_array)\n",
        "#     #     print(result)\n",
        "#     #     print(result.shape)\n",
        "#     #     print(type(result[0][0]))\n",
        "\n",
        "#         keypoint_arr = np.append(keypoint_arr, result, axis=0)\n",
        "#     return keypoint_arr"
      ],
      "id": "96637978",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d42e998"
      },
      "source": [
        "# def split_my_train_test_set(dataframe):\n",
        "#     # ['Time', 'ID_TYPE', 'Keypoint', 'Answer']\n",
        "\n",
        "#     id_data = dataframe[['ID_TYPE', 'Answer']].drop_duplicates(['ID_TYPE'])\n",
        "#     id_data = id_data.reset_index(drop=True)\n",
        "\n",
        "#     train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
        "#     train_test_split(id_data.drop('Answer', axis=1, inplace=False),\n",
        "#                      id_data['Answer'],\n",
        "#                      test_size=0.3,\n",
        "#                      stratify=id_data['Answer'],\n",
        "#                      random_state=0)\n",
        "#     train_x_data.reset_index(drop=True, inplace=True)\n",
        "#     test_x_data.reset_index(drop=True, inplace=True)\n",
        "#     train_t_data.reset_index(drop=True, inplace=True)\n",
        "#     test_t_data.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "#     result_train = pd.DataFrame( columns={'Time', 'ID_TYPE', 'Keypoints', 'Answer'} )\n",
        "#     result_test = pd.DataFrame( columns={'Time', 'ID_TYPE', 'Keypoints', 'Answer'} )\n",
        "\n",
        "# #     for k in tqdm(range(0, 3)):\n",
        "#     for k in tqdm(range(0, len(train_x_data))):\n",
        "#         pre_data = dataframe[ dataframe['ID_TYPE']==train_x_data.at[k, 'ID_TYPE'] ]\n",
        "#         result_train = result_train.append(pre_data)\n",
        "    \n",
        "#     for k in tqdm(range(0, len(test_x_data))):\n",
        "#         pre_data = dataframe[ dataframe['ID_TYPE']==test_x_data.at[k, 'ID_TYPE'] ]\n",
        "#         result_test = result_test.append(pre_data)\n",
        "\n",
        "#     result_train = result_train[['Time', 'ID_TYPE', 'Keypoints', 'Answer']]\n",
        "#     result_test = result_test[['Time', 'ID_TYPE', 'Keypoints', 'Answer']]\n",
        "    \n",
        "#     result_train.reset_index(drop=True, inplace=True)\n",
        "#     result_test.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "#     return result_train, result_test, train_t_data, test_t_data"
      ],
      "id": "9d42e998",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d25e7d22"
      },
      "source": [
        "# df_original = pd.read_csv('./train/dropped_train.csv', sep=',')\n",
        "\n",
        "# KEYPOINT = 32\n",
        "# KEYPOINT_MOD = 26\n",
        "\n",
        "# # CSV파일 구조:\n",
        "# # 45-1_001-C3 / 0 / 키포인트\n",
        "\n",
        "# # 5-7_016-C12\n",
        "# # 41-9_016-C12\n",
        "# # 6-7_603-C09\n",
        "\n",
        "# # df.head(50)\n",
        "\n",
        "# print(df_original[ df_original['Time']==8 ])\n",
        "\n",
        "# drop_index = df_original[ df_original['Time']==8 ].index\n",
        "# print(drop_index)\n",
        "# # new_test_df.loc[41448]\n",
        "# print(df_original.shape)\n",
        "\n",
        "# df = df_original.drop(drop_index, inplace=False)\n",
        "# df = df.reset_index(drop=True, inplace=False)\n",
        "\n",
        "# print(df.shape)"
      ],
      "id": "d25e7d22",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d08f34b"
      },
      "source": [
        "# df[\"ID_TYPE\"] = df[\"ID\"] + \"_\" + df[\"Person\"].map(str)\n",
        "# df_data = df.drop(['ID', 'Person'], axis=1)\n",
        "# df_data = df_data[['Time', 'ID_TYPE', 'Keypoints', 'Answer']]\n",
        "# print(df_data)"
      ],
      "id": "0d08f34b",
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "049d4e8a"
      },
      "source": [
        "# train_x, test_x, train_t, test_t = split_my_train_test_set(df_data)\n",
        "\n",
        "# train_x.head(50)\n",
        "# # test_x.head(50)\n",
        "\n",
        "# print(train_x.shape)\n",
        "# print(train_t.shape)\n",
        "\n",
        "# # x_data = df[['Keypoints']]\n",
        "# # t_data = np.zeros(len(x_data),)\n",
        "# # print(x_data)\n",
        "# # print(len(x_data))\n",
        "# # print(x_data.shape)\n",
        "# # # print(t_data)\n",
        "# # # t_data = df[['ID']]\n",
        "\n",
        "# # x_data_mod = get_keypoints_in_float(x_data)\n",
        "\n",
        "# # # print(keypoint.shape)\n",
        "# # # print(len(keypoint))\n",
        "    \n",
        "# # print(type(x_data_mod))\n",
        "# # print(x_data_mod)\n",
        "# # print(x_data_mod.shape)\n",
        "# # print(len(x_data_mod))\n",
        "# # print(x_data_mod[0])\n",
        "# # print(type(x_data_mod[0])) # <class 'str'>"
      ],
      "id": "049d4e8a",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e776d3c4"
      },
      "source": [
        "# train_x[ train_x['Time']==8 ]"
      ],
      "id": "e776d3c4",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fa67ae9"
      },
      "source": [
        "# drop_index = train_x[ train_x['Time']==8 ].index\n",
        "# print(drop_index)\n",
        "# # new_test_df.loc[41448]\n",
        "# print(train_x.shape)\n",
        "\n",
        "# train_x_mod = train_x.drop(drop_index, inplace=False)\n",
        "# train_x_mod = train_x_mod.reset_index(drop=True, inplace=False)\n",
        "\n",
        "# train_t_mod = train_t.drop(drop_index, inplace=False)\n",
        "# train_t_mod = train_t_mod.reset_index(drop=True, inplace=False)\n",
        "\n",
        "# # new_test_df\n",
        "# print(train_x_mod.shape)\n",
        "# print(train_t_mod.shape)"
      ],
      "id": "6fa67ae9",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d7c6315"
      },
      "source": [
        "# train_x_data = get_keypoints_in_float(train_x_mod[['Keypoints']])\n",
        "\n",
        "# print(train_x_data.shape)"
      ],
      "id": "2d7c6315",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ce1c86b"
      },
      "source": [
        "# # train_x_data.to_csv('./train/train_x_data.csv',  mode='w', header = True)\n",
        "# # train_x_data\n",
        "# # pd.DataFrame({'Keypoints': train_x_data}).to_csv('./train/train_x_data.csv',  mode='w', header = True)\n",
        "\n",
        "# np.savetxt('./train/train_x_data.csv',train_x_data,delimiter=\",\")\n",
        "\n",
        "# train_t_mod.to_csv('./train/train_t_mod.csv',  mode='w', header = True, index=False)\n",
        "# train_t_mod\n"
      ],
      "id": "4ce1c86b",
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81153a52",
        "outputId": "a12f4f7e-2ec1-4b65-b442-e302f9ffc504"
      },
      "source": [
        "from numpy import genfromtxt\n",
        "\n",
        "train_x_data_DF = genfromtxt('/content/drive/MyDrive/6조/train_x_train_t/train_x.csv', delimiter=',')\n",
        "train_t_mod_DF = pd.read_csv('/content/drive/MyDrive/6조/train_x_train_t/train_t.csv', sep=',')\n",
        "\n",
        "valid_x_data_DF = genfromtxt('/content/drive/MyDrive/6조/train_x_train_t/valid_x.csv', delimiter=',')\n",
        "valid_t_mod_DF = pd.read_csv('/content/drive/MyDrive/6조/train_x_train_t/valid_t.csv', sep=',')\n",
        "\n",
        "test_x_data_DF = genfromtxt('/content/drive/MyDrive/6조/train_x_train_t/test_x.csv', delimiter=',')\n",
        "test_t_mod_DF = pd.read_csv('/content/drive/MyDrive/6조/train_x_train_t/test_t.csv', sep=',')\n",
        "# print(train_x_data_DF)\n",
        "# print(train_x_data_DF.shape)\n",
        "# print(train_t_mod_DF)\n",
        "\n",
        "train_x_data = train_x_data_DF\n",
        "train_t_mod = train_t_mod_DF\n",
        "\n",
        "valid_x_data = valid_x_data_DF\n",
        "valid_t_mod = valid_t_mod_DF\n",
        "\n",
        "test_x_data = test_x_data_DF\n",
        "test_t_mod = test_t_mod_DF\n",
        "\n",
        "print(train_x_data)\n",
        "print(train_x_data.shape)\n",
        "print(type(train_x_data[0][0]))\n",
        "print(train_t_mod.shape)\n",
        "\n",
        "print(valid_x_data)\n",
        "print(valid_x_data.shape)\n",
        "print(type(valid_x_data[0][0]))\n",
        "print(valid_t_mod.shape)"
      ],
      "id": "81153a52",
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 940.  648.  958. ...  414. 1044.  470.]\n",
            " [ 940.  643.  966. ...  414. 1079.  479.]\n",
            " [1014.  628. 1005. ...  413. 1061.  469.]\n",
            " ...\n",
            " [ 904.  963.  929. ...  508. 1013.  683.]\n",
            " [ 904.  963.  929. ...  508. 1013.  683.]\n",
            " [ 904.  963.  929. ...  508. 1013.  683.]]\n",
            "(97904, 26)\n",
            "<class 'numpy.float64'>\n",
            "(12238, 1)\n",
            "[[ 920.  844.  915. ...  549.  821.  512.]\n",
            " [ 920.  844.  901. ...  587.  790.  643.]\n",
            " [ 746.  844.  784. ...  562.  798.  627.]\n",
            " ...\n",
            " [1113.  597. 1105. ...  324.  990.  394.]\n",
            " [1120.  602. 1106. ...  338.  991.  396.]\n",
            " [1120.  602. 1127. ...  344. 1026.  408.]]\n",
            "(41960, 26)\n",
            "<class 'numpy.float64'>\n",
            "(5245, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5ac87ca"
      },
      "source": [
        "import easydict\n",
        " \n",
        "args = easydict.EasyDict({\n",
        "        \"batchsize\": 1,\n",
        "        \"epoch\": 1,\n",
        "#         \"gpu\": 0,\n",
        "        \"out\": \"result\",\n",
        "        \"resume\": False,\n",
        "#         \"unit\": 1000,\n",
        "        \"validationsplit\": 0.2,\n",
        "        \"optimizer\": \"rmsprop\",\n",
        "        \"frame\": 8,\n",
        "#         \"optimizer\": \"Adam\",\n",
        "        \n",
        "})"
      ],
      "id": "c5ac87ca",
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab13a4a3"
      },
      "source": [
        "# print(train_x_data.shape)\n",
        "# temp = train_x_data.reshape(-1, args.frame, 26)\n",
        "# print(type(temp))"
      ],
      "id": "ab13a4a3",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a99e1713",
        "outputId": "ccf5e446-e791-40a9-d1e0-8f6d5043dd20"
      },
      "source": [
        "# [ -1, (한번에 들어갈 입력값 수), (좌표개수) ]\n",
        "# 13개의 x,y 좌표이므로 26개\n",
        "train_x = tf.reshape(train_x_data,[-1, args.frame, 26])\n",
        "train_x.shape"
      ],
      "id": "a99e1713",
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12238, 8, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47a1fae3",
        "outputId": "0181e7b4-b987-4029-98da-16ee37a3276f"
      },
      "source": [
        "train_t_mod.shape\n",
        "# print(type(train_t_mod[0]))\n",
        "# print(type(train_x_data[0][0]))"
      ],
      "id": "47a1fae3",
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12238, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7f31bda",
        "outputId": "d4d6d284-475e-4933-a4db-63507e0a32fd"
      },
      "source": [
        "train_t = tf.reshape(train_t_mod,[-1,1])\n",
        "train_t.shape"
      ],
      "id": "f7f31bda",
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12238, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-lzJptbziXp"
      },
      "source": [
        "val_x = tf.reshape(valid_x_data,[-1, args.frame, 26])\n",
        "val_t = tf.reshape(valid_t_mod,[-1,1])"
      ],
      "id": "4-lzJptbziXp",
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYIkQ6yj1riV"
      },
      "source": [
        "test_x = tf.reshape(test_x_data,[-1, args.frame, 26])\n",
        "test_t = tf.reshape(test_t_mod,[-1,1])"
      ],
      "id": "IYIkQ6yj1riV",
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3DcjpDjMo5t",
        "outputId": "63bac59b-b499-4080-e4b0-51cd83b681b2"
      },
      "source": [
        "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Dropout, Flatten, BatchNormalization, Input, Convolution2D, Activation,TimeDistributed\n",
        "from keras.layers import Input, multiply, concatenate, Activation, Masking, Reshape\n",
        "from keras.layers import GlobalAveragePooling1D, Permute, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def generate_model():\n",
        "    ip = Input(shape=(args.frame,26))\n",
        "\n",
        "    x = Masking()(ip)\n",
        "    x = LSTM(units = 50, return_sequences = True)(x)\n",
        "    x = LSTM(units=50)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "  \n",
        "    y = Reshape((208, 1))(ip)\n",
        "    y = Conv1D (kernel_size=3, filters=128, strides=3, padding='valid',kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    \n",
        "    y = Conv1D (kernel_size=3, filters=128, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "   \n",
        "    y = Conv1D (kernel_size=3, filters=128, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "    \n",
        "    y = Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = MaxPooling1D(pool_size=3, strides=3)(y) \n",
        "\n",
        "  \n",
        "    y = Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = MaxPooling1D(pool_size=2, strides=2)(y) \n",
        "     \n",
        "   \n",
        "    y = Dropout(0.2)(y)\n",
        "    y = Flatten()(y)\n",
        "    \n",
        "    x = concatenate([x, y])\n",
        "\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "\n",
        "    model = Model(ip, out)\n",
        "    #model.summary()\n",
        "    return model\n",
        "model = generate_model()\n",
        "model.summary()"
      ],
      "id": "j3DcjpDjMo5t",
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_44\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_75 (InputLayer)          [(None, 8, 26)]      0           []                               \n",
            "                                                                                                  \n",
            " reshape_60 (Reshape)           (None, 208, 1)       0           ['input_75[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_289 (Conv1D)            (None, 69, 128)      512         ['reshape_60[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_282 (Batch  (None, 69, 128)     512         ['conv1d_289[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_282 (Activation)    (None, 69, 128)      0           ['batch_normalization_282[0][0]']\n",
            "                                                                                                  \n",
            " conv1d_290 (Conv1D)            (None, 69, 128)      49280       ['activation_282[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_283 (Batch  (None, 69, 128)     512         ['conv1d_290[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_283 (Activation)    (None, 69, 128)      0           ['batch_normalization_283[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling1d_229 (MaxPooling1  (None, 23, 128)     0           ['activation_283[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_291 (Conv1D)            (None, 23, 128)      49280       ['max_pooling1d_229[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_284 (Batch  (None, 23, 128)     512         ['conv1d_291[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_284 (Activation)    (None, 23, 128)      0           ['batch_normalization_284[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling1d_230 (MaxPooling1  (None, 7, 128)      0           ['activation_284[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_292 (Conv1D)            (None, 7, 256)       98560       ['max_pooling1d_230[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_285 (Batch  (None, 7, 256)      1024        ['conv1d_292[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_285 (Activation)    (None, 7, 256)       0           ['batch_normalization_285[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling1d_231 (MaxPooling1  (None, 2, 256)      0           ['activation_285[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_293 (Conv1D)            (None, 2, 256)       196864      ['max_pooling1d_231[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_286 (Batch  (None, 2, 256)      1024        ['conv1d_293[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " masking_67 (Masking)           (None, 8, 26)        0           ['input_75[0][0]']               \n",
            "                                                                                                  \n",
            " activation_286 (Activation)    (None, 2, 256)       0           ['batch_normalization_286[0][0]']\n",
            "                                                                                                  \n",
            " lstm_136 (LSTM)                (None, 8, 50)        15400       ['masking_67[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling1d_232 (MaxPooling1  (None, 1, 256)      0           ['activation_286[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " lstm_137 (LSTM)                (None, 50)           20200       ['lstm_136[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_114 (Dropout)          (None, 1, 256)       0           ['max_pooling1d_232[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_113 (Dropout)          (None, 50)           0           ['lstm_137[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_46 (Flatten)           (None, 256)          0           ['dropout_114[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 306)          0           ['dropout_113[0][0]',            \n",
            "                                                                  'flatten_46[0][0]']             \n",
            "                                                                                                  \n",
            " dense_54 (Dense)               (None, 1)            307         ['concatenate_46[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 433,987\n",
            "Trainable params: 432,195\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec20df13"
      },
      "source": [
        "# #가벼운 모델 생성\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(32, input_shape=(args.frame,26)))\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(61, activation='softmax')) # 다중 분류\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# # Adam 최적화함수를 사용해보는 것도 고려해볼 것\n",
        "# # model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) # 다중 분류\n",
        "# model.compile(optimizer=args.optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "id": "ec20df13",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XLzXN2hS112",
        "outputId": "d4000424-bdeb-4731-9f36-2e6bf67a7f7b"
      },
      "source": [
        "num_models = 1\n",
        "model_list=[]\n",
        "\n",
        "for i in tqdm(range(num_models)):\n",
        "    model = generate_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    model.fit(train_x, train_t, epochs=15, batch_size=32,validation_data=(val_x, val_t))\n",
        "    model_list.append(model)\n",
        "\n",
        "# model.save(f\"model_{i}.h5\")"
      ],
      "id": "4XLzXN2hS112",
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "383/383 [==============================] - 26s 39ms/step - loss: 0.4408 - accuracy: 0.7904 - val_loss: 0.3953 - val_accuracy: 0.8219\n",
            "Epoch 2/15\n",
            "383/383 [==============================] - 12s 30ms/step - loss: 0.3509 - accuracy: 0.8412 - val_loss: 0.5681 - val_accuracy: 0.7676\n",
            "Epoch 3/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.3070 - accuracy: 0.8645 - val_loss: 0.4293 - val_accuracy: 0.8069\n",
            "Epoch 4/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.2715 - accuracy: 0.8827 - val_loss: 0.3073 - val_accuracy: 0.8667\n",
            "Epoch 5/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.2409 - accuracy: 0.8991 - val_loss: 0.2839 - val_accuracy: 0.8791\n",
            "Epoch 6/15\n",
            "383/383 [==============================] - 12s 30ms/step - loss: 0.2187 - accuracy: 0.9088 - val_loss: 0.2865 - val_accuracy: 0.8848\n",
            "Epoch 7/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.1980 - accuracy: 0.9176 - val_loss: 0.3184 - val_accuracy: 0.8713\n",
            "Epoch 8/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.1822 - accuracy: 0.9276 - val_loss: 0.2443 - val_accuracy: 0.8965\n",
            "Epoch 9/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.1620 - accuracy: 0.9342 - val_loss: 0.3277 - val_accuracy: 0.8810\n",
            "Epoch 10/15\n",
            "383/383 [==============================] - 12s 32ms/step - loss: 0.1458 - accuracy: 0.9422 - val_loss: 0.2149 - val_accuracy: 0.9201\n",
            "Epoch 11/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.1355 - accuracy: 0.9481 - val_loss: 0.1729 - val_accuracy: 0.9308\n",
            "Epoch 12/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.1166 - accuracy: 0.9543 - val_loss: 0.1837 - val_accuracy: 0.9283\n",
            "Epoch 13/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.1068 - accuracy: 0.9583 - val_loss: 0.1993 - val_accuracy: 0.9224\n",
            "Epoch 14/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.1004 - accuracy: 0.9603 - val_loss: 0.1828 - val_accuracy: 0.9285\n",
            "Epoch 15/15\n",
            "383/383 [==============================] - 12s 31ms/step - loss: 0.0861 - accuracy: 0.9663 - val_loss: 0.1878 - val_accuracy: 0.9279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [03:34<00:00, 214.56s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw1CxS0Ab1T-",
        "outputId": "394d2231-329e-41b6-e536-5a7bab16d938"
      },
      "source": [
        "import keras\n",
        "\n",
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/6조/model_0.h5')\n",
        "\n",
        "new_model.summary()"
      ],
      "id": "zw1CxS0Ab1T-",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_41\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_72 (InputLayer)          [(None, 8, 26)]      0           []                               \n",
            "                                                                                                  \n",
            " reshape_57 (Reshape)           (None, 208, 1)       0           ['input_72[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_274 (Conv1D)            (None, 69, 128)      512         ['reshape_57[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_267 (Batch  (None, 69, 128)     512         ['conv1d_274[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_267 (Activation)    (None, 69, 128)      0           ['batch_normalization_267[0][0]']\n",
            "                                                                                                  \n",
            " conv1d_275 (Conv1D)            (None, 69, 128)      49280       ['activation_267[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_268 (Batch  (None, 69, 128)     512         ['conv1d_275[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_268 (Activation)    (None, 69, 128)      0           ['batch_normalization_268[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling1d_217 (MaxPooling1  (None, 23, 128)     0           ['activation_268[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_276 (Conv1D)            (None, 23, 128)      49280       ['max_pooling1d_217[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_269 (Batch  (None, 23, 128)     512         ['conv1d_276[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_269 (Activation)    (None, 23, 128)      0           ['batch_normalization_269[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling1d_218 (MaxPooling1  (None, 7, 128)      0           ['activation_269[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_277 (Conv1D)            (None, 7, 256)       98560       ['max_pooling1d_218[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_270 (Batch  (None, 7, 256)      1024        ['conv1d_277[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_270 (Activation)    (None, 7, 256)       0           ['batch_normalization_270[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling1d_219 (MaxPooling1  (None, 2, 256)      0           ['activation_270[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_278 (Conv1D)            (None, 2, 256)       196864      ['max_pooling1d_219[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_271 (Batch  (None, 2, 256)      1024        ['conv1d_278[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " masking_64 (Masking)           (None, 8, 26)        0           ['input_72[0][0]']               \n",
            "                                                                                                  \n",
            " activation_271 (Activation)    (None, 2, 256)       0           ['batch_normalization_271[0][0]']\n",
            "                                                                                                  \n",
            " lstm_130 (LSTM)                (None, 8, 50)        15400       ['masking_64[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling1d_220 (MaxPooling1  (None, 1, 256)      0           ['activation_271[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " lstm_131 (LSTM)                (None, 50)           20200       ['lstm_130[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_108 (Dropout)          (None, 1, 256)       0           ['max_pooling1d_220[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_107 (Dropout)          (None, 50)           0           ['lstm_131[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_43 (Flatten)           (None, 256)          0           ['dropout_108[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 306)          0           ['dropout_107[0][0]',            \n",
            "                                                                  'flatten_43[0][0]']             \n",
            "                                                                                                  \n",
            " dense_51 (Dense)               (None, 1)            307         ['concatenate_43[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 433,987\n",
            "Trainable params: 432,195\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMM9w-aom98P",
        "outputId": "249346f6-e714-4f84-b5b8-a9c8d590b613"
      },
      "source": [
        "loss, mse = model.evaluate(test_x, test_t, batch_size=1)\n",
        "print('acc : ', mse)"
      ],
      "id": "OMM9w-aom98P",
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7494/7494 [==============================] - 66s 8ms/step - loss: 0.1866 - accuracy: 0.9347\n",
            "acc :  0.9347478151321411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsFmYqtD14cq",
        "outputId": "e775d0ba-2ef5-4244-bef0-a0858545953c"
      },
      "source": [
        "y_predict = model.predict(test_x)\n",
        "print(y_predict)"
      ],
      "id": "UsFmYqtD14cq",
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.6515366e-04]\n",
            " [9.9965429e-01]\n",
            " [2.0504068e-01]\n",
            " ...\n",
            " [6.2665808e-01]\n",
            " [9.6797413e-01]\n",
            " [9.9875641e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjfnPEMpn_pD"
      },
      "source": [
        ""
      ],
      "id": "JjfnPEMpn_pD"
    }
  ]
}